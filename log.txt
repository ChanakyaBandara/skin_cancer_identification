C:\Users\ishan\PycharmProjects\skin_cancer_identification\venv\Scripts\python.exe C:/Users/ishan/PycharmProjects/skin_cancer_identification/temp_run.py
Processing image 0
Processing image 1000
Processing image 2000
Processing image 3000
Processing image 4000
Processing image 5000
Processing image 6000
Processing image 7000
Processing image 8000
Processing image 9000
Processing image 10000
2023-09-09 00:01:28.888000: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE SSE2 SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 input_1 (InputLayer)        [(None, 128, 128, 3)]     0

 block1_conv1 (Conv2D)       (None, 128, 128, 64)      1792

 block1_conv2 (Conv2D)       (None, 128, 128, 64)      36928

 block1_pool (MaxPooling2D)  (None, 64, 64, 64)        0

 block2_conv1 (Conv2D)       (None, 64, 64, 128)       73856

 block2_conv2 (Conv2D)       (None, 64, 64, 128)       147584

 block2_pool (MaxPooling2D)  (None, 32, 32, 128)       0

 block3_conv1 (Conv2D)       (None, 32, 32, 256)       295168

 block3_conv2 (Conv2D)       (None, 32, 32, 256)       590080

 block3_conv3 (Conv2D)       (None, 32, 32, 256)       590080

 block3_pool (MaxPooling2D)  (None, 16, 16, 256)       0

 block4_conv1 (Conv2D)       (None, 16, 16, 512)       1180160

 block4_conv2 (Conv2D)       (None, 16, 16, 512)       2359808

 block4_conv3 (Conv2D)       (None, 16, 16, 512)       2359808

 block4_pool (MaxPooling2D)  (None, 8, 8, 512)         0

 block5_conv1 (Conv2D)       (None, 8, 8, 512)         2359808

 block5_conv2 (Conv2D)       (None, 8, 8, 512)         2359808

 block5_conv3 (Conv2D)       (None, 8, 8, 512)         2359808

 block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0

 global_average_pooling2d (  (None, 512)               0
 GlobalAveragePooling2D)

 dense (Dense)               (None, 128)               65664

 dense_1 (Dense)             (None, 7)                 903

=================================================================
Total params: 14781255 (56.39 MB)
Trainable params: 14781255 (56.39 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________
Epoch 1/50
62/62 [==============================] - 189s 3s/step - loss: 1.2207 - accuracy: 0.6418 - val_loss: 1.9065 - val_accuracy: 0.1093
Epoch 2/50
62/62 [==============================] - 188s 3s/step - loss: 1.1566 - accuracy: 0.6667 - val_loss: 1.8979 - val_accuracy: 0.1101
Epoch 3/50
62/62 [==============================] - 189s 3s/step - loss: 1.1500 - accuracy: 0.6682 - val_loss: 1.9960 - val_accuracy: 0.1090
Epoch 4/50
62/62 [==============================] - 189s 3s/step - loss: 1.1536 - accuracy: 0.6667 - val_loss: 2.0138 - val_accuracy: 0.1067
Epoch 5/50
62/62 [==============================] - 191s 3s/step - loss: 1.1487 - accuracy: 0.6687 - val_loss: 2.0839 - val_accuracy: 0.1077
Epoch 6/50
62/62 [==============================] - 189s 3s/step - loss: 1.1403 - accuracy: 0.6682 - val_loss: 2.0825 - val_accuracy: 0.1080
Epoch 7/50
62/62 [==============================] - 189s 3s/step - loss: 1.1455 - accuracy: 0.6692 - val_loss: 2.1205 - val_accuracy: 0.1085
Epoch 8/50
62/62 [==============================] - 190s 3s/step - loss: 1.1516 - accuracy: 0.6682 - val_loss: 2.1655 - val_accuracy: 0.1088
Epoch 9/50
62/62 [==============================] - 190s 3s/step - loss: 1.1443 - accuracy: 0.6672 - val_loss: 2.2289 - val_accuracy: 0.1082
Epoch 10/50
62/62 [==============================] - 187s 3s/step - loss: 1.1535 - accuracy: 0.6672 - val_loss: 2.2678 - val_accuracy: 0.1086
Epoch 11/50
62/62 [==============================] - 187s 3s/step - loss: 1.1412 - accuracy: 0.6702 - val_loss: 2.2717 - val_accuracy: 0.1088
Epoch 12/50
62/62 [==============================] - 187s 3s/step - loss: 1.1359 - accuracy: 0.6697 - val_loss: 2.2966 - val_accuracy: 0.1084
Epoch 13/50
62/62 [==============================] - 187s 3s/step - loss: 1.1514 - accuracy: 0.6657 - val_loss: 2.3264 - val_accuracy: 0.1086
Epoch 14/50
62/62 [==============================] - 187s 3s/step - loss: 1.1461 - accuracy: 0.6687 - val_loss: 2.3408 - val_accuracy: 0.1086
Epoch 15/50
62/62 [==============================] - 187s 3s/step - loss: 1.1464 - accuracy: 0.6682 - val_loss: 2.3857 - val_accuracy: 0.1086
Epoch 16/50
62/62 [==============================] - 188s 3s/step - loss: 1.1542 - accuracy: 0.6677 - val_loss: 2.4092 - val_accuracy: 0.1085
Epoch 17/50
62/62 [==============================] - 189s 3s/step - loss: 1.1498 - accuracy: 0.6677 - val_loss: 2.4744 - val_accuracy: 0.1086
Epoch 18/50
62/62 [==============================] - 191s 3s/step - loss: 1.1415 - accuracy: 0.6707 - val_loss: 2.4194 - val_accuracy: 0.1085
Epoch 19/50
62/62 [==============================] - 188s 3s/step - loss: 1.1388 - accuracy: 0.6672 - val_loss: 2.3922 - val_accuracy: 0.1085
Epoch 20/50
62/62 [==============================] - 189s 3s/step - loss: 1.1420 - accuracy: 0.6668 - val_loss: 2.4308 - val_accuracy: 0.1081
Epoch 21/50
62/62 [==============================] - 188s 3s/step - loss: 1.1330 - accuracy: 0.6687 - val_loss: 2.4959 - val_accuracy: 0.1082
Epoch 22/50
62/62 [==============================] - 187s 3s/step - loss: 1.1470 - accuracy: 0.6662 - val_loss: 2.5076 - val_accuracy: 0.1084
Epoch 23/50
62/62 [==============================] - 188s 3s/step - loss: 1.1415 - accuracy: 0.6667 - val_loss: 2.5034 - val_accuracy: 0.1086
Epoch 24/50
62/62 [==============================] - 187s 3s/step - loss: 1.1500 - accuracy: 0.6672 - val_loss: 2.5722 - val_accuracy: 0.1086
Epoch 25/50
62/62 [==============================] - 188s 3s/step - loss: 1.1373 - accuracy: 0.6678 - val_loss: 2.5194 - val_accuracy: 0.1082
Epoch 26/50
62/62 [==============================] - 188s 3s/step - loss: 1.1379 - accuracy: 0.6677 - val_loss: 2.5680 - val_accuracy: 0.1086
Epoch 27/50
62/62 [==============================] - 188s 3s/step - loss: 1.1327 - accuracy: 0.6712 - val_loss: 2.5654 - val_accuracy: 0.1086
Epoch 28/50
62/62 [==============================] - 190s 3s/step - loss: 1.1369 - accuracy: 0.6677 - val_loss: 2.6129 - val_accuracy: 0.1085
Epoch 29/50
62/62 [==============================] - 188s 3s/step - loss: 1.1434 - accuracy: 0.6677 - val_loss: 2.5860 - val_accuracy: 0.1088
Epoch 30/50
62/62 [==============================] - 16763s 275s/step - loss: 1.1429 - accuracy: 0.6662 - val_loss: 2.6135 - val_accuracy: 0.1084
Epoch 31/50
62/62 [==============================] - 195s 3s/step - loss: 1.1406 - accuracy: 0.6697 - val_loss: 2.5877 - val_accuracy: 0.1088
Epoch 32/50
62/62 [==============================] - 190s 3s/step - loss: 1.1436 - accuracy: 0.6673 - val_loss: 2.5646 - val_accuracy: 0.1085
Epoch 33/50
62/62 [==============================] - 191s 3s/step - loss: 1.1409 - accuracy: 0.6667 - val_loss: 2.5988 - val_accuracy: 0.1085
Epoch 34/50
62/62 [==============================] - 189s 3s/step - loss: 1.1437 - accuracy: 0.6677 - val_loss: 2.5726 - val_accuracy: 0.1086
Epoch 35/50
62/62 [==============================] - 190s 3s/step - loss: 1.1455 - accuracy: 0.6667 - val_loss: 2.6332 - val_accuracy: 0.1085
Epoch 36/50
62/62 [==============================] - 190s 3s/step - loss: 1.1430 - accuracy: 0.6672 - val_loss: 2.6171 - val_accuracy: 0.1086
Epoch 37/50
62/62 [==============================] - 189s 3s/step - loss: 1.1334 - accuracy: 0.6682 - val_loss: 2.6086 - val_accuracy: 0.1088
Epoch 38/50
62/62 [==============================] - 190s 3s/step - loss: 1.1367 - accuracy: 0.6682 - val_loss: 2.6484 - val_accuracy: 0.1086
Epoch 39/50
62/62 [==============================] - 189s 3s/step - loss: 1.1344 - accuracy: 0.6692 - val_loss: 2.6636 - val_accuracy: 0.1089
Epoch 40/50
62/62 [==============================] - 191s 3s/step - loss: 1.1422 - accuracy: 0.6667 - val_loss: 2.6128 - val_accuracy: 0.1085
Epoch 41/50
62/62 [==============================] - 189s 3s/step - loss: 1.1310 - accuracy: 0.6687 - val_loss: 2.6754 - val_accuracy: 0.1089
Epoch 42/50
62/62 [==============================] - 189s 3s/step - loss: 1.1397 - accuracy: 0.6682 - val_loss: 2.6675 - val_accuracy: 0.1089
Epoch 43/50
62/62 [==============================] - 190s 3s/step - loss: 1.1408 - accuracy: 0.6667 - val_loss: 2.6732 - val_accuracy: 0.1089
Epoch 44/50
62/62 [==============================] - 190s 3s/step - loss: 1.1331 - accuracy: 0.6697 - val_loss: 2.6890 - val_accuracy: 0.1086
Epoch 45/50
62/62 [==============================] - 190s 3s/step - loss: 1.1220 - accuracy: 0.6722 - val_loss: 2.6610 - val_accuracy: 0.1085
Epoch 46/50
62/62 [==============================] - 189s 3s/step - loss: 1.1378 - accuracy: 0.6662 - val_loss: 2.6843 - val_accuracy: 0.1088
Epoch 47/50
62/62 [==============================] - 190s 3s/step - loss: 1.1474 - accuracy: 0.6651 - val_loss: 2.7147 - val_accuracy: 0.1089
Epoch 48/50
62/62 [==============================] - 189s 3s/step - loss: 1.1383 - accuracy: 0.6672 - val_loss: 2.7026 - val_accuracy: 0.1086
Epoch 49/50
62/62 [==============================] - 190s 3s/step - loss: 1.1307 - accuracy: 0.6702 - val_loss: 2.7186 - val_accuracy: 0.1089
Epoch 50/50
62/62 [==============================] - 189s 3s/step - loss: 1.1399 - accuracy: 0.6657 - val_loss: 2.7016 - val_accuracy: 0.1086
C:\Users\ishan\PycharmProjects\skin_cancer_identification\venv\lib\site-packages\keras\src\engine\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.
  saving_api.save_model(
--- 26085.989577293396 VGG16 - seconds ---
Processing image 0
Processing image 1000
Processing image 2000
Processing image 3000
Processing image 4000
Processing image 5000
Processing image 6000
Processing image 7000
Processing image 8000
Processing image 9000
Processing image 10000
Model: "model_1"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to
==================================================================================================
 input_2 (InputLayer)        [(None, 128, 128, 3)]        0         []

 conv1_pad (ZeroPadding2D)   (None, 134, 134, 3)          0         ['input_2[0][0]']

 conv1_conv (Conv2D)         (None, 64, 64, 64)           9472      ['conv1_pad[0][0]']

 conv1_bn (BatchNormalizati  (None, 64, 64, 64)           256       ['conv1_conv[0][0]']
 on)

 conv1_relu (Activation)     (None, 64, 64, 64)           0         ['conv1_bn[0][0]']

 pool1_pad (ZeroPadding2D)   (None, 66, 66, 64)           0         ['conv1_relu[0][0]']

 pool1_pool (MaxPooling2D)   (None, 32, 32, 64)           0         ['pool1_pad[0][0]']

 conv2_block1_1_conv (Conv2  (None, 32, 32, 64)           4160      ['pool1_pool[0][0]']
 D)

 conv2_block1_1_bn (BatchNo  (None, 32, 32, 64)           256       ['conv2_block1_1_conv[0][0]']
 rmalization)

 conv2_block1_1_relu (Activ  (None, 32, 32, 64)           0         ['conv2_block1_1_bn[0][0]']
 ation)

 conv2_block1_2_conv (Conv2  (None, 32, 32, 64)           36928     ['conv2_block1_1_relu[0][0]']
 D)

 conv2_block1_2_bn (BatchNo  (None, 32, 32, 64)           256       ['conv2_block1_2_conv[0][0]']
 rmalization)

 conv2_block1_2_relu (Activ  (None, 32, 32, 64)           0         ['conv2_block1_2_bn[0][0]']
 ation)

 conv2_block1_0_conv (Conv2  (None, 32, 32, 256)          16640     ['pool1_pool[0][0]']
 D)

 conv2_block1_3_conv (Conv2  (None, 32, 32, 256)          16640     ['conv2_block1_2_relu[0][0]']
 D)

 conv2_block1_0_bn (BatchNo  (None, 32, 32, 256)          1024      ['conv2_block1_0_conv[0][0]']
 rmalization)

 conv2_block1_3_bn (BatchNo  (None, 32, 32, 256)          1024      ['conv2_block1_3_conv[0][0]']
 rmalization)

 conv2_block1_add (Add)      (None, 32, 32, 256)          0         ['conv2_block1_0_bn[0][0]',
                                                                     'conv2_block1_3_bn[0][0]']

 conv2_block1_out (Activati  (None, 32, 32, 256)          0         ['conv2_block1_add[0][0]']
 on)

 conv2_block2_1_conv (Conv2  (None, 32, 32, 64)           16448     ['conv2_block1_out[0][0]']
 D)

 conv2_block2_1_bn (BatchNo  (None, 32, 32, 64)           256       ['conv2_block2_1_conv[0][0]']
 rmalization)

 conv2_block2_1_relu (Activ  (None, 32, 32, 64)           0         ['conv2_block2_1_bn[0][0]']
 ation)

 conv2_block2_2_conv (Conv2  (None, 32, 32, 64)           36928     ['conv2_block2_1_relu[0][0]']
 D)

 conv2_block2_2_bn (BatchNo  (None, 32, 32, 64)           256       ['conv2_block2_2_conv[0][0]']
 rmalization)

 conv2_block2_2_relu (Activ  (None, 32, 32, 64)           0         ['conv2_block2_2_bn[0][0]']
 ation)

 conv2_block2_3_conv (Conv2  (None, 32, 32, 256)          16640     ['conv2_block2_2_relu[0][0]']
 D)

 conv2_block2_3_bn (BatchNo  (None, 32, 32, 256)          1024      ['conv2_block2_3_conv[0][0]']
 rmalization)

 conv2_block2_add (Add)      (None, 32, 32, 256)          0         ['conv2_block1_out[0][0]',
                                                                     'conv2_block2_3_bn[0][0]']

 conv2_block2_out (Activati  (None, 32, 32, 256)          0         ['conv2_block2_add[0][0]']
 on)

 conv2_block3_1_conv (Conv2  (None, 32, 32, 64)           16448     ['conv2_block2_out[0][0]']
 D)

 conv2_block3_1_bn (BatchNo  (None, 32, 32, 64)           256       ['conv2_block3_1_conv[0][0]']
 rmalization)

 conv2_block3_1_relu (Activ  (None, 32, 32, 64)           0         ['conv2_block3_1_bn[0][0]']
 ation)

 conv2_block3_2_conv (Conv2  (None, 32, 32, 64)           36928     ['conv2_block3_1_relu[0][0]']
 D)

 conv2_block3_2_bn (BatchNo  (None, 32, 32, 64)           256       ['conv2_block3_2_conv[0][0]']
 rmalization)

 conv2_block3_2_relu (Activ  (None, 32, 32, 64)           0         ['conv2_block3_2_bn[0][0]']
 ation)

 conv2_block3_3_conv (Conv2  (None, 32, 32, 256)          16640     ['conv2_block3_2_relu[0][0]']
 D)

 conv2_block3_3_bn (BatchNo  (None, 32, 32, 256)          1024      ['conv2_block3_3_conv[0][0]']
 rmalization)

 conv2_block3_add (Add)      (None, 32, 32, 256)          0         ['conv2_block2_out[0][0]',
                                                                     'conv2_block3_3_bn[0][0]']

 conv2_block3_out (Activati  (None, 32, 32, 256)          0         ['conv2_block3_add[0][0]']
 on)

 conv3_block1_1_conv (Conv2  (None, 16, 16, 128)          32896     ['conv2_block3_out[0][0]']
 D)

 conv3_block1_1_bn (BatchNo  (None, 16, 16, 128)          512       ['conv3_block1_1_conv[0][0]']
 rmalization)

 conv3_block1_1_relu (Activ  (None, 16, 16, 128)          0         ['conv3_block1_1_bn[0][0]']
 ation)

 conv3_block1_2_conv (Conv2  (None, 16, 16, 128)          147584    ['conv3_block1_1_relu[0][0]']
 D)

 conv3_block1_2_bn (BatchNo  (None, 16, 16, 128)          512       ['conv3_block1_2_conv[0][0]']
 rmalization)

 conv3_block1_2_relu (Activ  (None, 16, 16, 128)          0         ['conv3_block1_2_bn[0][0]']
 ation)

 conv3_block1_0_conv (Conv2  (None, 16, 16, 512)          131584    ['conv2_block3_out[0][0]']
 D)

 conv3_block1_3_conv (Conv2  (None, 16, 16, 512)          66048     ['conv3_block1_2_relu[0][0]']
 D)

 conv3_block1_0_bn (BatchNo  (None, 16, 16, 512)          2048      ['conv3_block1_0_conv[0][0]']
 rmalization)

 conv3_block1_3_bn (BatchNo  (None, 16, 16, 512)          2048      ['conv3_block1_3_conv[0][0]']
 rmalization)

 conv3_block1_add (Add)      (None, 16, 16, 512)          0         ['conv3_block1_0_bn[0][0]',
                                                                     'conv3_block1_3_bn[0][0]']

 conv3_block1_out (Activati  (None, 16, 16, 512)          0         ['conv3_block1_add[0][0]']
 on)

 conv3_block2_1_conv (Conv2  (None, 16, 16, 128)          65664     ['conv3_block1_out[0][0]']
 D)

 conv3_block2_1_bn (BatchNo  (None, 16, 16, 128)          512       ['conv3_block2_1_conv[0][0]']
 rmalization)

 conv3_block2_1_relu (Activ  (None, 16, 16, 128)          0         ['conv3_block2_1_bn[0][0]']
 ation)

 conv3_block2_2_conv (Conv2  (None, 16, 16, 128)          147584    ['conv3_block2_1_relu[0][0]']
 D)

 conv3_block2_2_bn (BatchNo  (None, 16, 16, 128)          512       ['conv3_block2_2_conv[0][0]']
 rmalization)

 conv3_block2_2_relu (Activ  (None, 16, 16, 128)          0         ['conv3_block2_2_bn[0][0]']
 ation)

 conv3_block2_3_conv (Conv2  (None, 16, 16, 512)          66048     ['conv3_block2_2_relu[0][0]']
 D)

 conv3_block2_3_bn (BatchNo  (None, 16, 16, 512)          2048      ['conv3_block2_3_conv[0][0]']
 rmalization)

 conv3_block2_add (Add)      (None, 16, 16, 512)          0         ['conv3_block1_out[0][0]',
                                                                     'conv3_block2_3_bn[0][0]']

 conv3_block2_out (Activati  (None, 16, 16, 512)          0         ['conv3_block2_add[0][0]']
 on)

 conv3_block3_1_conv (Conv2  (None, 16, 16, 128)          65664     ['conv3_block2_out[0][0]']
 D)

 conv3_block3_1_bn (BatchNo  (None, 16, 16, 128)          512       ['conv3_block3_1_conv[0][0]']
 rmalization)

 conv3_block3_1_relu (Activ  (None, 16, 16, 128)          0         ['conv3_block3_1_bn[0][0]']
 ation)

 conv3_block3_2_conv (Conv2  (None, 16, 16, 128)          147584    ['conv3_block3_1_relu[0][0]']
 D)

 conv3_block3_2_bn (BatchNo  (None, 16, 16, 128)          512       ['conv3_block3_2_conv[0][0]']
 rmalization)

 conv3_block3_2_relu (Activ  (None, 16, 16, 128)          0         ['conv3_block3_2_bn[0][0]']
 ation)

 conv3_block3_3_conv (Conv2  (None, 16, 16, 512)          66048     ['conv3_block3_2_relu[0][0]']
 D)

 conv3_block3_3_bn (BatchNo  (None, 16, 16, 512)          2048      ['conv3_block3_3_conv[0][0]']
 rmalization)

 conv3_block3_add (Add)      (None, 16, 16, 512)          0         ['conv3_block2_out[0][0]',
                                                                     'conv3_block3_3_bn[0][0]']

 conv3_block3_out (Activati  (None, 16, 16, 512)          0         ['conv3_block3_add[0][0]']
 on)

 conv3_block4_1_conv (Conv2  (None, 16, 16, 128)          65664     ['conv3_block3_out[0][0]']
 D)

 conv3_block4_1_bn (BatchNo  (None, 16, 16, 128)          512       ['conv3_block4_1_conv[0][0]']
 rmalization)

 conv3_block4_1_relu (Activ  (None, 16, 16, 128)          0         ['conv3_block4_1_bn[0][0]']
 ation)

 conv3_block4_2_conv (Conv2  (None, 16, 16, 128)          147584    ['conv3_block4_1_relu[0][0]']
 D)

 conv3_block4_2_bn (BatchNo  (None, 16, 16, 128)          512       ['conv3_block4_2_conv[0][0]']
 rmalization)

 conv3_block4_2_relu (Activ  (None, 16, 16, 128)          0         ['conv3_block4_2_bn[0][0]']
 ation)

 conv3_block4_3_conv (Conv2  (None, 16, 16, 512)          66048     ['conv3_block4_2_relu[0][0]']
 D)

 conv3_block4_3_bn (BatchNo  (None, 16, 16, 512)          2048      ['conv3_block4_3_conv[0][0]']
 rmalization)

 conv3_block4_add (Add)      (None, 16, 16, 512)          0         ['conv3_block3_out[0][0]',
                                                                     'conv3_block4_3_bn[0][0]']

 conv3_block4_out (Activati  (None, 16, 16, 512)          0         ['conv3_block4_add[0][0]']
 on)

 conv4_block1_1_conv (Conv2  (None, 8, 8, 256)            131328    ['conv3_block4_out[0][0]']
 D)

 conv4_block1_1_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv4_block1_1_conv[0][0]']
 rmalization)

 conv4_block1_1_relu (Activ  (None, 8, 8, 256)            0         ['conv4_block1_1_bn[0][0]']
 ation)

 conv4_block1_2_conv (Conv2  (None, 8, 8, 256)            590080    ['conv4_block1_1_relu[0][0]']
 D)

 conv4_block1_2_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv4_block1_2_conv[0][0]']
 rmalization)

 conv4_block1_2_relu (Activ  (None, 8, 8, 256)            0         ['conv4_block1_2_bn[0][0]']
 ation)

 conv4_block1_0_conv (Conv2  (None, 8, 8, 1024)           525312    ['conv3_block4_out[0][0]']
 D)

 conv4_block1_3_conv (Conv2  (None, 8, 8, 1024)           263168    ['conv4_block1_2_relu[0][0]']
 D)

 conv4_block1_0_bn (BatchNo  (None, 8, 8, 1024)           4096      ['conv4_block1_0_conv[0][0]']
 rmalization)

 conv4_block1_3_bn (BatchNo  (None, 8, 8, 1024)           4096      ['conv4_block1_3_conv[0][0]']
 rmalization)

 conv4_block1_add (Add)      (None, 8, 8, 1024)           0         ['conv4_block1_0_bn[0][0]',
                                                                     'conv4_block1_3_bn[0][0]']

 conv4_block1_out (Activati  (None, 8, 8, 1024)           0         ['conv4_block1_add[0][0]']
 on)

 conv4_block2_1_conv (Conv2  (None, 8, 8, 256)            262400    ['conv4_block1_out[0][0]']
 D)

 conv4_block2_1_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv4_block2_1_conv[0][0]']
 rmalization)

 conv4_block2_1_relu (Activ  (None, 8, 8, 256)            0         ['conv4_block2_1_bn[0][0]']
 ation)

 conv4_block2_2_conv (Conv2  (None, 8, 8, 256)            590080    ['conv4_block2_1_relu[0][0]']
 D)

 conv4_block2_2_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv4_block2_2_conv[0][0]']
 rmalization)

 conv4_block2_2_relu (Activ  (None, 8, 8, 256)            0         ['conv4_block2_2_bn[0][0]']
 ation)

 conv4_block2_3_conv (Conv2  (None, 8, 8, 1024)           263168    ['conv4_block2_2_relu[0][0]']
 D)

 conv4_block2_3_bn (BatchNo  (None, 8, 8, 1024)           4096      ['conv4_block2_3_conv[0][0]']
 rmalization)

 conv4_block2_add (Add)      (None, 8, 8, 1024)           0         ['conv4_block1_out[0][0]',
                                                                     'conv4_block2_3_bn[0][0]']

 conv4_block2_out (Activati  (None, 8, 8, 1024)           0         ['conv4_block2_add[0][0]']
 on)

 conv4_block3_1_conv (Conv2  (None, 8, 8, 256)            262400    ['conv4_block2_out[0][0]']
 D)

 conv4_block3_1_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv4_block3_1_conv[0][0]']
 rmalization)

 conv4_block3_1_relu (Activ  (None, 8, 8, 256)            0         ['conv4_block3_1_bn[0][0]']
 ation)

 conv4_block3_2_conv (Conv2  (None, 8, 8, 256)            590080    ['conv4_block3_1_relu[0][0]']
 D)

 conv4_block3_2_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv4_block3_2_conv[0][0]']
 rmalization)

 conv4_block3_2_relu (Activ  (None, 8, 8, 256)            0         ['conv4_block3_2_bn[0][0]']
 ation)

 conv4_block3_3_conv (Conv2  (None, 8, 8, 1024)           263168    ['conv4_block3_2_relu[0][0]']
 D)

 conv4_block3_3_bn (BatchNo  (None, 8, 8, 1024)           4096      ['conv4_block3_3_conv[0][0]']
 rmalization)

 conv4_block3_add (Add)      (None, 8, 8, 1024)           0         ['conv4_block2_out[0][0]',
                                                                     'conv4_block3_3_bn[0][0]']

 conv4_block3_out (Activati  (None, 8, 8, 1024)           0         ['conv4_block3_add[0][0]']
 on)

 conv4_block4_1_conv (Conv2  (None, 8, 8, 256)            262400    ['conv4_block3_out[0][0]']
 D)

 conv4_block4_1_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv4_block4_1_conv[0][0]']
 rmalization)

 conv4_block4_1_relu (Activ  (None, 8, 8, 256)            0         ['conv4_block4_1_bn[0][0]']
 ation)

 conv4_block4_2_conv (Conv2  (None, 8, 8, 256)            590080    ['conv4_block4_1_relu[0][0]']
 D)

 conv4_block4_2_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv4_block4_2_conv[0][0]']
 rmalization)

 conv4_block4_2_relu (Activ  (None, 8, 8, 256)            0         ['conv4_block4_2_bn[0][0]']
 ation)

 conv4_block4_3_conv (Conv2  (None, 8, 8, 1024)           263168    ['conv4_block4_2_relu[0][0]']
 D)

 conv4_block4_3_bn (BatchNo  (None, 8, 8, 1024)           4096      ['conv4_block4_3_conv[0][0]']
 rmalization)

 conv4_block4_add (Add)      (None, 8, 8, 1024)           0         ['conv4_block3_out[0][0]',
                                                                     'conv4_block4_3_bn[0][0]']

 conv4_block4_out (Activati  (None, 8, 8, 1024)           0         ['conv4_block4_add[0][0]']
 on)

 conv4_block5_1_conv (Conv2  (None, 8, 8, 256)            262400    ['conv4_block4_out[0][0]']
 D)

 conv4_block5_1_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv4_block5_1_conv[0][0]']
 rmalization)

 conv4_block5_1_relu (Activ  (None, 8, 8, 256)            0         ['conv4_block5_1_bn[0][0]']
 ation)

 conv4_block5_2_conv (Conv2  (None, 8, 8, 256)            590080    ['conv4_block5_1_relu[0][0]']
 D)

 conv4_block5_2_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv4_block5_2_conv[0][0]']
 rmalization)

 conv4_block5_2_relu (Activ  (None, 8, 8, 256)            0         ['conv4_block5_2_bn[0][0]']
 ation)

 conv4_block5_3_conv (Conv2  (None, 8, 8, 1024)           263168    ['conv4_block5_2_relu[0][0]']
 D)

 conv4_block5_3_bn (BatchNo  (None, 8, 8, 1024)           4096      ['conv4_block5_3_conv[0][0]']
 rmalization)

 conv4_block5_add (Add)      (None, 8, 8, 1024)           0         ['conv4_block4_out[0][0]',
                                                                     'conv4_block5_3_bn[0][0]']

 conv4_block5_out (Activati  (None, 8, 8, 1024)           0         ['conv4_block5_add[0][0]']
 on)

 conv4_block6_1_conv (Conv2  (None, 8, 8, 256)            262400    ['conv4_block5_out[0][0]']
 D)

 conv4_block6_1_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv4_block6_1_conv[0][0]']
 rmalization)

 conv4_block6_1_relu (Activ  (None, 8, 8, 256)            0         ['conv4_block6_1_bn[0][0]']
 ation)

 conv4_block6_2_conv (Conv2  (None, 8, 8, 256)            590080    ['conv4_block6_1_relu[0][0]']
 D)

 conv4_block6_2_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv4_block6_2_conv[0][0]']
 rmalization)

 conv4_block6_2_relu (Activ  (None, 8, 8, 256)            0         ['conv4_block6_2_bn[0][0]']
 ation)

 conv4_block6_3_conv (Conv2  (None, 8, 8, 1024)           263168    ['conv4_block6_2_relu[0][0]']
 D)

 conv4_block6_3_bn (BatchNo  (None, 8, 8, 1024)           4096      ['conv4_block6_3_conv[0][0]']
 rmalization)

 conv4_block6_add (Add)      (None, 8, 8, 1024)           0         ['conv4_block5_out[0][0]',
                                                                     'conv4_block6_3_bn[0][0]']

 conv4_block6_out (Activati  (None, 8, 8, 1024)           0         ['conv4_block6_add[0][0]']
 on)

 conv5_block1_1_conv (Conv2  (None, 4, 4, 512)            524800    ['conv4_block6_out[0][0]']
 D)

 conv5_block1_1_bn (BatchNo  (None, 4, 4, 512)            2048      ['conv5_block1_1_conv[0][0]']
 rmalization)

 conv5_block1_1_relu (Activ  (None, 4, 4, 512)            0         ['conv5_block1_1_bn[0][0]']
 ation)

 conv5_block1_2_conv (Conv2  (None, 4, 4, 512)            2359808   ['conv5_block1_1_relu[0][0]']
 D)

 conv5_block1_2_bn (BatchNo  (None, 4, 4, 512)            2048      ['conv5_block1_2_conv[0][0]']
 rmalization)

 conv5_block1_2_relu (Activ  (None, 4, 4, 512)            0         ['conv5_block1_2_bn[0][0]']
 ation)

 conv5_block1_0_conv (Conv2  (None, 4, 4, 2048)           2099200   ['conv4_block6_out[0][0]']
 D)

 conv5_block1_3_conv (Conv2  (None, 4, 4, 2048)           1050624   ['conv5_block1_2_relu[0][0]']
 D)

 conv5_block1_0_bn (BatchNo  (None, 4, 4, 2048)           8192      ['conv5_block1_0_conv[0][0]']
 rmalization)

 conv5_block1_3_bn (BatchNo  (None, 4, 4, 2048)           8192      ['conv5_block1_3_conv[0][0]']
 rmalization)

 conv5_block1_add (Add)      (None, 4, 4, 2048)           0         ['conv5_block1_0_bn[0][0]',
                                                                     'conv5_block1_3_bn[0][0]']

 conv5_block1_out (Activati  (None, 4, 4, 2048)           0         ['conv5_block1_add[0][0]']
 on)

 conv5_block2_1_conv (Conv2  (None, 4, 4, 512)            1049088   ['conv5_block1_out[0][0]']
 D)

 conv5_block2_1_bn (BatchNo  (None, 4, 4, 512)            2048      ['conv5_block2_1_conv[0][0]']
 rmalization)

 conv5_block2_1_relu (Activ  (None, 4, 4, 512)            0         ['conv5_block2_1_bn[0][0]']
 ation)

 conv5_block2_2_conv (Conv2  (None, 4, 4, 512)            2359808   ['conv5_block2_1_relu[0][0]']
 D)

 conv5_block2_2_bn (BatchNo  (None, 4, 4, 512)            2048      ['conv5_block2_2_conv[0][0]']
 rmalization)

 conv5_block2_2_relu (Activ  (None, 4, 4, 512)            0         ['conv5_block2_2_bn[0][0]']
 ation)

 conv5_block2_3_conv (Conv2  (None, 4, 4, 2048)           1050624   ['conv5_block2_2_relu[0][0]']
 D)

 conv5_block2_3_bn (BatchNo  (None, 4, 4, 2048)           8192      ['conv5_block2_3_conv[0][0]']
 rmalization)

 conv5_block2_add (Add)      (None, 4, 4, 2048)           0         ['conv5_block1_out[0][0]',
                                                                     'conv5_block2_3_bn[0][0]']

 conv5_block2_out (Activati  (None, 4, 4, 2048)           0         ['conv5_block2_add[0][0]']
 on)

 conv5_block3_1_conv (Conv2  (None, 4, 4, 512)            1049088   ['conv5_block2_out[0][0]']
 D)

 conv5_block3_1_bn (BatchNo  (None, 4, 4, 512)            2048      ['conv5_block3_1_conv[0][0]']
 rmalization)

 conv5_block3_1_relu (Activ  (None, 4, 4, 512)            0         ['conv5_block3_1_bn[0][0]']
 ation)

 conv5_block3_2_conv (Conv2  (None, 4, 4, 512)            2359808   ['conv5_block3_1_relu[0][0]']
 D)

 conv5_block3_2_bn (BatchNo  (None, 4, 4, 512)            2048      ['conv5_block3_2_conv[0][0]']
 rmalization)

 conv5_block3_2_relu (Activ  (None, 4, 4, 512)            0         ['conv5_block3_2_bn[0][0]']
 ation)

 conv5_block3_3_conv (Conv2  (None, 4, 4, 2048)           1050624   ['conv5_block3_2_relu[0][0]']
 D)

 conv5_block3_3_bn (BatchNo  (None, 4, 4, 2048)           8192      ['conv5_block3_3_conv[0][0]']
 rmalization)

 conv5_block3_add (Add)      (None, 4, 4, 2048)           0         ['conv5_block2_out[0][0]',
                                                                     'conv5_block3_3_bn[0][0]']

 conv5_block3_out (Activati  (None, 4, 4, 2048)           0         ['conv5_block3_add[0][0]']
 on)

 global_average_pooling2d_1  (None, 2048)                 0         ['conv5_block3_out[0][0]']
  (GlobalAveragePooling2D)

 dense_2 (Dense)             (None, 128)                  262272    ['global_average_pooling2d_1[0
                                                                    ][0]']

 dense_3 (Dense)             (None, 7)                    903       ['dense_2[0][0]']

==================================================================================================
Total params: 23850887 (90.98 MB)
Trainable params: 23797767 (90.78 MB)
Non-trainable params: 53120 (207.50 KB)
__________________________________________________________________________________________________
WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
Epoch 1/50
62/62 [==============================] - 118s 2s/step - loss: 1.1762 - accuracy: 0.6616 - val_loss: 1.8387 - val_accuracy: 0.1109
Epoch 2/50
62/62 [==============================] - 110s 2s/step - loss: 1.1350 - accuracy: 0.6687 - val_loss: 2.1199 - val_accuracy: 0.1104
Epoch 3/50
62/62 [==============================] - 108s 2s/step - loss: 1.1360 - accuracy: 0.6672 - val_loss: 2.3291 - val_accuracy: 0.1107
Epoch 4/50
62/62 [==============================] - 110s 2s/step - loss: 1.1416 - accuracy: 0.6687 - val_loss: 2.5838 - val_accuracy: 0.1107
Epoch 5/50
62/62 [==============================] - 113s 2s/step - loss: 1.1322 - accuracy: 0.6692 - val_loss: 2.5756 - val_accuracy: 0.1105
Epoch 6/50
62/62 [==============================] - 113s 2s/step - loss: 1.1296 - accuracy: 0.6697 - val_loss: 2.6598 - val_accuracy: 0.1109
Epoch 7/50
62/62 [==============================] - 113s 2s/step - loss: 1.1343 - accuracy: 0.6662 - val_loss: 2.8307 - val_accuracy: 0.1105
Epoch 8/50
62/62 [==============================] - ETA: 0s - loss: 1.1282 - accuracy: 0.6662